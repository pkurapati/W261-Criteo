{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteo Click Through Rate Prediction \n",
    "Final project for W261 - Machine Learning at Scale  \n",
    "By Ben Arnoldy, Kenneth Chen, Nick Conidas, Rohini Kashibatla, Pavan Kurapati\n",
    "\n",
    "INTRO TEXT, QUESTION 1 TEXT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Algorithm Explanation\n",
    "Create your own toy example that matches the dataset provided and use this toy example to explain the math behind the algorithm that you will perform.  \n",
    "\n",
    "Logistic regression carries over some of the same concepts as linear regression but with some important differences. Fundamentally, we are still training a model that results in an equation for a line. So our trained model looks like a vector of coefficients in a linear equation:  \n",
    "  \n",
    "<center>Linear equation: $y = \\beta_0 + \\beta_1 \\cdot X_1 ... + \\beta_m \\cdot X_m$</center>    \n",
    "  \n",
    "<center>Our model: $[\\beta_0, \\beta_1, ... \\beta_m]$</center>    \n",
    "where m is number of features and $\\beta_0$, or intercept, is a bias term.  \n",
    "As with linear regression, we use this line to make predictions. In linear regression, we take a new datapoint of features (x's), plug into the linear equation with our model coefficients, and get a predicted y value. With logistic regression, it's more complicated since we are taking continuous variable inputs and trying to arrive at a binary classification output. The line we are drawing is a decision boundary above which we classify the input as 1 and below which we classify the input as 0. We need to perform some additional steps to convert the y value prediction, which is a continuous variable, to a final answer of a 0 or a 1. First, we put the predicted y value through a sigmoid function, which outputs a continuous value between 0 and 1 that represents a probability:  \n",
    "  \n",
    "<center>P(class=1) = \\frac{1} {1 + e^{-z}}</center>\n",
    "  \n",
    "where z is the y value prediction (i.e. mx+b).  Once we have these probabilities, we need to pick a decision boundary between 0 and 1. One logical default value for that boundary is 0.5. So if the probability is greater than 0.5, classify the sample as 1, otherwise classify it as 0.  \n",
    "  \n",
    "Like with linear regression, in order to parallelize the training of the linear model we can't do a closed-form solution but must treat it as an optimization problem with gradient descent. Fortunately, the Log Loss or Cross-Entropy Loss method described above gives us a convex equation, allowing us to use gradient descent with the confidence of not hitting local minima.  \n",
    "  \n",
    "Objective: $f(w) = \\sum_{i=1}^{n}log(1+exp(-y_i w^T x_i))$  \n",
    "$\\frac{df}{dw} = \\sum_{i=1}^{n}\\frac{1}{1+exp(-y_i w x_i)}\\cdot\\frac{d[1+exp(-y_i w x_i)}{dw}$  \n",
    "$              = \\sum_{i=1}^{n}\\frac{exp(-y_i w x_i)}{1+exp(-y_i w^T x_i)}\\cdot\\frac{d(-y_i w x_i)}{dw}$  \n",
    "$              = \\sum_{i=1}^{n}\\frac{exp(-y_i w x_i)}{1+exp(-y_i w^T x_i)}(-y_i x_i)$  \n",
    "$              = \\sum_{i=1}^{n}[1 - \\frac{1}{1+exp(-y_i w x_i)}](-y_i x_i)$  \n",
    "$              = \\sum_{i=1}^{n}[\\frac{1}{1+exp(-y_i w x_i)} + 1](y_i x_i)$  \n",
    "$  \\nabla_w f =\\sum_{i=1}^{n}[\\frac{1}{1+exp(-y_i w^T x_i)} + 1](y_i x_i)$\n",
    "  \n",
    "This gets expressed in the code below as a spark job as follows:  \n",
    ".map(lambda x: (1 / (1 + np.exp(-x[1]*np.dot(W, x[0])))-1) * x[1] * np.array(x[0]))  \n",
    ".reduce(lambda x, y: x + y)\n",
    "\n",
    "A LITTLE BIT MORE ON THE CALCULATING LOSS...\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numbers\n",
    "\n",
    "from pyspark.ml.feature import FeatureHasher\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import FeatureHasher\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"fproj_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into Spark RDD \n",
    "projectRDD = sc.textFile('gs://w261-bucket-pav/notebooks/data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def extractLabel(line):\n",
    "    \"\"\"Mapper to extract labels\"\"\"\n",
    "    label = line[0]\n",
    "    yield label\n",
    "\n",
    "def extractTrain(line):\n",
    "    \"\"\" Extracts train data\"\"\"\n",
    "    train = line[1:]\n",
    "    yield train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string row to individual features and label\n",
    "projectRDD = projectRDD.map(lambda x: x.split('\\t')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the RDD into train, val and test\n",
    "trainRDD,valRDD,testRDD=projectRDD.randomSplit([0.8, 0.1, 0.1],2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... held out 4585453 records for validation, 4586499 records for test and assigned 36668665 for training.\n"
     ]
    }
   ],
   "source": [
    "print(f\"... held out {valRDD.count()} records for validation, {testRDD.count()} records for test and assigned {trainRDD.count()} for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(element):\n",
    "    \"\"\"\n",
    "    Map record_csv_string --> (tuple,of,fields)\n",
    "    \"\"\"\n",
    "    n_elements = len(element)\n",
    "    fields = np.array(element)\n",
    "    features,click = fields[1:], fields[0]\n",
    "    return(features, click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRDDCached = trainRDD.map(parse).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract a toy dataset\n",
    "To just show the workings of the algorithm, we want a small number of rows and avoid types of data that we can't handle. That means we need to remove categorical features and NAs. We explored a number of possibilities for handling the NA problem:\n",
    "1. Simply removing all rows with missing data. The problem: That results in the loss of approximately 90 percent of the data. \n",
    "2. Creating dummy variables for each integer feature that would be set to True if the feature had data or False if the feature had no data. Then, we would replace all NAs in the integer features with zeros. So, for I1 there would be an I1_missing, for I2 an I2_missing, and so on. We did not see an accuracy gain from those Ix_missing features and instead saw L1 Normalization zeroing those out. \n",
    "3. Replace the NAs with mean values of each feature. This seemed to strike the right balance between preserving data and not creating unnecessary features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_categorical(x):\n",
    "    features = x[0]\n",
    "    label = x[1]\n",
    "    # We are interested in C6,C9, C14, C17, C20, C22, C23\n",
    "    # These are at index 18,21,26,29,32,34,35\n",
    "    c_index_list = [18,21,26,29,32,34,35]\n",
    "    new_arr = np.array(features[0:13],dtype=str)\n",
    "    for index in c_index_list:\n",
    "        new_arr = np.append(new_arr,features[index])\n",
    "    yield((new_arr,label))\n",
    "\n",
    "new_trainRDDCached = trainRDDCached.flatMap(remove_categorical).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all blanks in new_trainRDDCached integer values with their means\n",
    "\n",
    "def replace_int_null(x):\n",
    "    features = x[0]\n",
    "    label = int(x[1])\n",
    "    for i in range(13):\n",
    "        if features[i]==\"\":\n",
    "            features[i] = float(mean_dict_bc.value[i+1])\n",
    "        else:\n",
    "            features[i] = float(features[i])\n",
    "    features = features.astype(float)\n",
    "    yield((features,label))\n",
    "\n",
    "def replace_int_null_noInt(x):\n",
    "    features = x[0]\n",
    "    label = int(x[1])\n",
    "    for i in range(13):\n",
    "        if features[i]==\"\":\n",
    "            features[i] = float(mean_dict_bc.value[i+1])\n",
    "        else:\n",
    "            features[i] = float(features[i])\n",
    "    yield((features,label))\n",
    "    \n",
    "def replace_char_null(x):\n",
    "    features = x[0]\n",
    "    label = int(x[1])\n",
    "    for i in range(13,len(features)):\n",
    "        if features[i]==\"\":\n",
    "            features[i] = 'AAAA'\n",
    "    yield((features,label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array(['2.0', '0.0', '44.0', '1.0', '102.0', '8.0', '2.0', '2.0', '4.0',\n",
       "         '1.0', '1.0', '0.991518', '4.0', 'fe6b92e5', 'a73ee510',\n",
       "         'b28479f6', '07c540c4', '5840adea', 'AAAA', '3a171ecb'],\n",
       "        dtype='<U8'), 0)]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_trainRDDCached = new_trainRDDCached.flatMap(replace_int_null_noInt)\\\n",
    "                                    .flatMap(replace_char_null).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  2.      ,   0.      ,  44.      ,   1.      , 102.      ,\n",
       "           8.      ,   2.      ,   2.      ,   4.      ,   1.      ,\n",
       "           1.      ,   0.991518,   4.      ]), 0)]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IntFeatRDD = IntFeatRDD.flatMap(replace_int_null).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the toy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataRDD):\n",
    "    \"\"\"\n",
    "    Scale and center data round mean of each feature.\n",
    "    Args:\n",
    "        dataRDD - records are tuples of (features_array, y)\n",
    "    Returns:\n",
    "        normedRDD - records are tuples of (features_array, y)\n",
    "    \"\"\"\n",
    "    featureMeans = dataRDD.map(lambda x: x[0]).mean()\n",
    "    featureStdev = np.sqrt(dataRDD.map(lambda x: x[0]).variance())\n",
    "    normedRDD = dataRDD.map(lambda x: (np.divide((x[0] - featureMeans), featureStdev), x[1]))        \n",
    "    return normedRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "normedRDD = normalize(IntFeatRDD).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run logistic regression, include L1, L2 normalization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLoss(dataRDD, W):\n",
    "    \"\"\"\n",
    "    Compute loss using log loss or cross entropy formula.\n",
    "    Args:\n",
    "        dataRDD - each record is a tuple of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    Adapted from sources:\n",
    "    * Homework 4 code for W261\n",
    "    * https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html\n",
    "    * https://www.internalpointers.com/post/cost-function-logistic-regression\n",
    "    \"\"\"\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "\n",
    "    loss = augmentedData.map(lambda x: (-np.dot(x[1],np.log(1 / (1 + np.exp(-np.dot(W, x[0]))))) -\\\n",
    "                                        np.dot((1-x[1]),np.log(1- (1 / (1 + np.exp(-np.dot(W, x[0])))))), 1)) \\\n",
    "                        .reduce(lambda x,y:(x[0]+y[0], x[1]+y[1]))\n",
    "\n",
    "    loss = float(loss[0])/loss[1]\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GDUpdate_wReg(dataRDD, W, N, learningRate = 0.1, regType = None, regParam = 0.1):\n",
    "    \"\"\"\n",
    "    Perform one gradient descent step/update with ridge or lasso regularization.\n",
    "    Args:\n",
    "        dataRDD - tuple of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "        learningRate - (float) defaults to 0.1\n",
    "        regType - (str) 'ridge' or 'lasso', defaults to None\n",
    "        regParam - (float) regularization term coefficient\n",
    "    Returns:\n",
    "        model   - (array) updated coefficients, bias still at index 0\n",
    "    Adapted from sources:\n",
    "    * Homework 4 code from W261\n",
    "    * Notebook cited by Jimi in asynch: https://nbviewer.jupyter.org/urls/dl.dropbox.com/s/r20ff7q0yni5kiu/LogisticRegression-Spark-Notebook.ipynb\n",
    "    \"\"\"\n",
    "    \n",
    "    # augmented data\n",
    "    # this puts a 1.0 in front of x's to pass thru bias term\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])) \n",
    "    \n",
    "    new_model = None\n",
    "    \n",
    "    # calculate the gradient\n",
    "    \n",
    "    gradient = augmentedData.map(lambda x: (1 / (1 + np.exp(-x[1]*np.dot(W, x[0])))-1) * x[1] * np.array(x[0]))\\\n",
    "                    .reduce(lambda x, y: x + y)\n",
    "    if regType == \"ridge\":\n",
    "        wReg = W * 1\n",
    "        wReg = np.append([0], wReg[1:]) # remove the bias term ahead of regularization        \n",
    "    elif regType == \"lasso\":\n",
    "        wReg = W * 1\n",
    "        wReg = np.append([0], wReg[1:]) # remove the bias term ahead of regularization\n",
    "        wReg = (wReg>0).astype(int) * 2-1\n",
    "    else:\n",
    "        wReg = np.zeros(W.shape[0])\n",
    "    gradient = gradient + regParam * wReg  #gradient:  GD of Squared Error+ GD of regularized term \n",
    "    new_model = W - learningRate * gradient / N\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientDescent_wReg(trainRDD, testRDD, wInit, nSteps = 20, learningRate = 0.1,\n",
    "                         regType = None, regParam = 0.1, verbose = True):\n",
    "    \"\"\"\n",
    "    Perform nSteps iterations of regularized gradient descent and \n",
    "    track loss on a test and train set. Return lists of\n",
    "    test/train loss and the models themselves.\n",
    "    Adapted from sources:\n",
    "    * Homework 4 code from W261\n",
    "    * Notebook cited by Jimi in asynch: https://nbviewer.jupyter.org/urls/dl.dropbox.com/s/r20ff7q0yni5kiu/LogisticRegression-Spark-Notebook.ipynb    \n",
    "    \"\"\"\n",
    "    # initialize lists to track model performance\n",
    "    train_history, test_history, model_history = [], [], []\n",
    "    \n",
    "    # calculate N here so you don't have to do it in the for looped function call\n",
    "    N = trainRDD.count()\n",
    "\n",
    "    # make a starter set of weights if none provided\n",
    "    featureLen = len(trainRDD.take(1)[0][0])\n",
    "    if wInit is None:\n",
    "        w = np.random.normal(size=featureLen) # w should be broadcasted if it is large\n",
    "    else:\n",
    "        w = wInit\n",
    "    model = w\n",
    "    \n",
    "    # perform nSteps updates & compute test and train loss after each\n",
    "    for idx in range(nSteps):  \n",
    "   \n",
    "        # update the model\n",
    "        model = GDUpdate_wReg(trainRDD, model, N, learningRate, regType, regParam)\n",
    "        \n",
    "        # keep track of test/train loss for plotting\n",
    "        training_loss = LogLoss(trainRDD, model)\n",
    "        test_loss = LogLoss(testRDD, model)\n",
    "        train_history.append(training_loss)\n",
    "        test_history.append(test_loss)\n",
    "        model_history.append(model)\n",
    "        \n",
    "        # console output if desired\n",
    "        if verbose:\n",
    "            print(\"----------\")\n",
    "            print(f\"STEP: {idx+1}\")\n",
    "            print(f\"training loss: {training_loss}\")\n",
    "            print(f\"test loss: {test_loss}\")\n",
    "            print(f\"Model: {[round(w,3) for w in model]}\")\n",
    "    return train_history, test_history, model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test and train a logistic regression model with L1 regularization\n",
    "\n",
    "# initialize the weights with a bias term determined after some testing and zeros for coeffecients\n",
    "wInit = np.array([-0.77, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "trainRDD, testRDD = normedNONARDD.randomSplit([0.8,0.2], seed = 5)\n",
    "start = time.time()\n",
    "lasso_results = GradientDescent_wReg(trainRDD, testRDD, wInit, nSteps = 10, regParam = 0.1)\n",
    "print(f\"\\n... trained {len(lasso_results[2])} iterations in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make error curve plots that show declining loss as walk down the gradient\n",
    "# from HW4 code\n",
    "\n",
    "def plotErrorCurves(trainLoss, testLoss, title = None):\n",
    "    \"\"\"\n",
    "    Helper function for plotting.\n",
    "    Args: trainLoss (list of log loss) , testLoss (list of log loss)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize = (16,8))\n",
    "    x = list(range(len(trainLoss)))[1:]\n",
    "    ax.plot(x, trainLoss[1:], 'k--', label='Training Loss')\n",
    "    ax.plot(x, testLoss[1:], 'r--', label='Test Loss')\n",
    "    ax.legend(loc='upper right', fontsize='x-large')\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Log Loss')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv files\n",
    "# from HW4 code\n",
    "\n",
    "trainLoss, testLoss, models = lasso_results\n",
    "np.savetxt(PWD + '/data/lasso_models.csv', np.array(models), delimiter=',')\n",
    "np.savetxt(PWD + '/data/lasso_loss.csv', np.array([trainLoss, testLoss]), delimiter=',')\n",
    "plotErrorCurves(trainLoss, testLoss, title = 'Lasso Regression Error Curves' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best model from files\n",
    "# from HW4 code\n",
    "\n",
    "saved_models = np.loadtxt(PWD + '/data/lasso_models.csv', dtype=float, delimiter=',')\n",
    "best_model = saved_models[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the coeffecients as L1 steps increase\n",
    "# adapted from HW4 code\n",
    "\n",
    "def plotCoeffs(models, featureNames, title):\n",
    "    \"\"\"\n",
    "    Helper Function to show how coefficients change as we train.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize = (15,8))\n",
    "    X = list(range(len(models)))\n",
    "    for data, name in zip(models.T, featureNames):\n",
    "        if name == \"Bias\":\n",
    "            continue\n",
    "        ax.plot(X, data, label=name)\n",
    "    ax.plot(X,[0]*len(X), 'k--')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show\n",
    "    \n",
    "#use if starting with the models with the missing data features\n",
    "#plotCoeffs(saved_models, ['Bias'] + numeric_features + missing, \"Lasso Coefficients over 50 GD steps\")\n",
    "\n",
    "# use if starting with the model where NA rows were dropped\n",
    "plotCoeffs(saved_models, ['Bias'] + numeric_features, \"Lasso Coefficients over 50 GD steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy of the model\n",
    "# from learning here: https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html\n",
    "\n",
    "def sigmoid(row):\n",
    "    sig = []\n",
    "    for z in row:\n",
    "        sig.append(1/(1+np.exp(-z)))\n",
    "    return sig\n",
    "\n",
    "def decision_boundary(prob):\n",
    "    return 1 if prob >= .5 else 0\n",
    "\n",
    "def classify(predictions):\n",
    "    '''\n",
    "    input  - N element array of predictions between 0 and 1\n",
    "    output - N element array of 0s (False) and 1s (True)\n",
    "    '''\n",
    "    classifications = []\n",
    "    for prediction in predictions:\n",
    "        classifications.append(decision_boundary(prediction))\n",
    "    return classifications\n",
    "\n",
    "def calc_accuracy(predicted_labels, actual_labels):\n",
    "    error_count = 0\n",
    "    num_predictions = len(actual_labels)\n",
    "    for compare in range(num_predictions):\n",
    "        if predicted_labels[compare] != actual_labels[compare]:\n",
    "            error_count += 1\n",
    "    return 1.0 - (float(error_count) / num_predictions)\n",
    "\n",
    "def compare(x,y):\n",
    "    return int(x != y)\n",
    "\n",
    "coeffs = best_lasso[1:] # coefficients\n",
    "b = best_lasso[0] # bias term\n",
    "actual_labels = testRDD.map(lambda x: x[1]).collect()\n",
    "\n",
    "# regular version -- good for toy example, may need spark below on big data\n",
    "mxb = testRDD.map(lambda x: np.dot(coeffs, x[0])+b).collect() # mx+b\n",
    "probabilities = sigmoid(mxb) # put through sigmoid\n",
    "predictions = classify(probabilities) # put through a decision boundary\n",
    "print (\"accuracy is\", calc_accuracy(predictions, actual_labels))\n",
    "\n",
    "# spark version below if regular version crashes with big data\n",
    "\"\"\"\n",
    "error_count = testRDD.map(lambda x: (np.dot(coeffs, x[0])+b, x[1])) \\\n",
    "                    .map(lambda x: (1/(1+np.exp(-x[0])), x[1])) \\\n",
    "                    .map(lambda x: (decision_boundary(x[0]), x[1])) \\\n",
    "                    .map(lambda x: (compare(x[0],x[1]),1)) \\\n",
    "                    .reduce(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "\n",
    "print(\"accuracy is\", 1.0 - (float(error_count[0]) / error_count[1]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: EDA......"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
