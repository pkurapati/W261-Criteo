{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "__`MIDS w261: Machine Learning at Scale | UC Berkeley School of Information | Fall 2018`__  \n",
    "Throughout this course you’ve engaged with key principles required to develop scalable machine learning analyses for structured and unstructured data. Working in Hadoop Streaming and Spark you’ve learned to translate common machine learning algorithms into Map-Reduce style implementations. You’ve developed the ability to evaluate Machine Learning approaches both in terms of their predictive performance as well as their scalability. For the final project you will demonstrate these skills by solving a machine learning challenge on a new dataset. Your job is to perform Click Through Rate prediction on a large dataset of Criteo advertising data made public as part of a Kaggle competition a few years back. As you perform your analysis, keep in mind that we are not grading you on the final performance of your model or how ‘advanced’ the techniques you use but rather on your ability to explain and develop a scalable machine learning approach to answering a real question.\n",
    "\n",
    "More about the dataset:\n",
    "https://www.kaggle.com/c/criteo-display-ad-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Set-Up\n",
    "Before starting your homework run the following cells to confirm your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.ml.feature import FeatureHasher\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import FeatureHasher\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"fproj_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -n 1000 data/train.txt > data/train1000.txt\n",
    "#!tail -n 200 data/train.txt > data/test200.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Load a text file and convert each line to a Row.\n",
    "lines = sc.textFile(\"data/train.txt\")\n",
    "parts = lines.map(lambda l: l.split(\"\\t\"))\n",
    "projectTrain = parts.map(lambda p: Row(label=int(p[0]), I1=p[1], I2=p[2],\\\n",
    "                    I3=p[3], I4=p[4], I5=p[5], I6=p[6],\\\n",
    "                    I7=p[7], I8=p[8], I9=p[9], I10=p[10],\\\n",
    "                    I11=p[11], I12=p[12], I13=p[13], C1=p[14], C2=p[15], C3=p[16],\\\n",
    "                    C4=p[17], C5=p[18], C6=p[19], C7=p[20], C8=p[21], C9=p[22],\\\n",
    "                    C10=p[23], C11=p[24], C12=p[25], C13=p[26], C14=p[27], C15=p[28],\\\n",
    "                    C16=p[29], C17=p[30], C18=p[31], C19=p[32], C20=p[33], C21=p[34],\\\n",
    "                    C22=p[35], C23=p[36], C24=p[37], C25=p[38], C26=p[39]))\n",
    "\n",
    "# Infer the schema, and register the DataFrame as a table.\n",
    "trainDF = sqlContext.createDataFrame(projectTrain)\n",
    "trainDF.registerTempTable(\"trainTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF,valDF,testDF=trainDF.randomSplit([0.6, 0.2, 0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.count()\n",
    "testDF.count()\n",
    "valDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- C1: string (nullable = true)\n",
      " |-- C10: string (nullable = true)\n",
      " |-- C11: string (nullable = true)\n",
      " |-- C12: string (nullable = true)\n",
      " |-- C13: string (nullable = true)\n",
      " |-- C14: string (nullable = true)\n",
      " |-- C15: string (nullable = true)\n",
      " |-- C16: string (nullable = true)\n",
      " |-- C17: string (nullable = true)\n",
      " |-- C18: string (nullable = true)\n",
      " |-- C19: string (nullable = true)\n",
      " |-- C2: string (nullable = true)\n",
      " |-- C20: string (nullable = true)\n",
      " |-- C21: string (nullable = true)\n",
      " |-- C22: string (nullable = true)\n",
      " |-- C23: string (nullable = true)\n",
      " |-- C24: string (nullable = true)\n",
      " |-- C25: string (nullable = true)\n",
      " |-- C26: string (nullable = true)\n",
      " |-- C3: string (nullable = true)\n",
      " |-- C4: string (nullable = true)\n",
      " |-- C5: string (nullable = true)\n",
      " |-- C6: string (nullable = true)\n",
      " |-- C7: string (nullable = true)\n",
      " |-- C8: string (nullable = true)\n",
      " |-- C9: string (nullable = true)\n",
      " |-- I1: string (nullable = true)\n",
      " |-- I10: string (nullable = true)\n",
      " |-- I11: string (nullable = true)\n",
      " |-- I12: string (nullable = true)\n",
      " |-- I13: string (nullable = true)\n",
      " |-- I2: string (nullable = true)\n",
      " |-- I3: string (nullable = true)\n",
      " |-- I4: string (nullable = true)\n",
      " |-- I5: string (nullable = true)\n",
      " |-- I6: string (nullable = true)\n",
      " |-- I7: string (nullable = true)\n",
      " |-- I8: string (nullable = true)\n",
      " |-- I9: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n",
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.printSchema()\n",
    "trainDF.select('label').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a text file and convert each line to a Row.\n",
    "lines = sc.textFile(\"data/test200.txt\")\n",
    "parts = lines.map(lambda l: l.split(\"\\t\"))\n",
    "projectTest = parts.map(lambda p: Row(label=int(p[0]), I1=p[1], I2=p[2],\\\n",
    "                    I3=p[3], I4=p[4], I5=p[5], I6=p[6],\\\n",
    "                    I7=p[7], I8=p[8], I9=p[9], I10=p[10],\\\n",
    "                    I11=p[11], I12=p[12], I13=p[13], C1=p[14], C2=p[15], C3=p[16],\\\n",
    "                    C4=p[17], C5=p[18], C6=p[19], C7=p[20], C8=p[21], C9=p[22],\\\n",
    "                    C10=p[23], C11=p[24], C12=p[25], C13=p[26], C14=p[27], C15=p[28],\\\n",
    "                    C16=p[29], C17=p[30], C18=p[31], C19=p[32], C20=p[33], C21=p[34],\\\n",
    "                    C22=p[35], C23=p[36], C24=p[37], C25=p[38], C26=p[39]))\n",
    "\n",
    "# Infer the schema, and register the DataFrame as a table.\n",
    "testDF = sqlContext.createDataFrame(projectTest)\n",
    "testDF.registerTempTable(\"trainTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                                                                                                                     |\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |(262144,[16677,45494,58516,62755,85868,105839,114826,121731,136999,153709,158464,171091,186439,204452,212354,218268,231205,259623],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,1.0,1.0])|\n",
      "|0    |(262144,[67625,68022,85868,88321,90447,101856,105425,114826,121731,153709,174084,176922,200921,207319,212354,226221,244352,259623],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,1.0,1.0])|\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainhasher = FeatureHasher(inputCols=[\"label\",\"I1\",\"I2\",\"I3\",\"I4\",\"I5\",\"I6\",\"I7\",\"I8\",\"I9\",\"I10\",\"I11\",\"I12\",\"C1\", \"C2\", \"C3\", \"C14\",\"C5\"],\n",
    "                       outputCol=\"features\")\n",
    "#trainDF.select(\"label\",\"I1\",\"I2\",\"I3\",\"I4\",\"I5\",\"I6\",\"I7\",\"I8\",\"I9\",\"I10\",\"I11\",\"I12\",\"C1\", \"C2\", \"C3\", \"C14\",\"C5\").show(2)\n",
    "featurizedTrain = trainhasher.transform(trainDF)\n",
    "#featurizedTrain.show(3)\n",
    "featurizedTrain.select(\"label\",\"features\").show(2,truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+---+---+----+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+\n",
      "|label| I1|  I2| I3| I4|  I5| I6| I7| I8| I9|I10|I11|I12|      C1|      C2|      C3|     C14|      C5|\n",
      "+-----+---+----+---+---+----+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+\n",
      "|    0|  0|   1|  4|   |5947| 61|  4|  3| 54|  0|  1|   |05db9164|287130e0|167110dc|07d13a8f|25c83c98|\n",
      "|    1|  0|1794|   |   |1316|104|  1| 14| 94|  0|  1|   |05db9164|3f0d3f28|0eb4724f|07d13a8f|4cf72387|\n",
      "+-----+---+----+---+---+----+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(262144,[7735,8820,36853,45494,61561,88321,113048,114826,126920,126973,133845,150344,150414,153709,191209,212354,226055,258496],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,1.0])     |\n",
      "|(262144,[36853,47086,88321,113048,113165,114826,126973,133845,144779,151145,165659,176890,188916,212354,222967,226055,229299,258153],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testhasher = FeatureHasher(inputCols=[\"label\",\"I1\",\"I2\",\"I3\",\"I4\",\"I5\",\"I6\",\"I7\",\"I8\",\"I9\",\"I10\",\"I11\",\"I12\",\"C1\", \"C2\", \"C3\", \"C14\",\"C5\"],\n",
    "                       outputCol=\"features\")\n",
    "testDF.select(\"label\",\"I1\",\"I2\",\"I3\",\"I4\",\"I5\",\"I6\",\"I7\",\"I8\",\"I9\",\"I10\",\"I11\",\"I12\",\"C1\", \"C2\", \"C3\", \"C14\",\"C5\").show(2)\n",
    "featurizedTest = testhasher.transform(testDF)\n",
    "\n",
    "featurizedTest.select(\"features\").show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_4d92ae50b901df42f77e\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\",featuresCol=\"features\",maxIter = 10)\n",
    "lrModel = lr.fit(featurizedTrain)\n",
    "print(lrModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---+---+---+---+---+----+---+---+----+---+---+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "|      C1|     C10|     C11|     C12|     C13|     C14|     C15|     C16|     C17|     C18|     C19|      C2|     C20|     C21|     C22|     C23|     C24|     C25|     C26|      C3|      C4|      C5|      C6|      C7|      C8|      C9| I1|I10|I11|I12|I13|  I2| I3| I4|  I5| I6| I7| I8| I9|label|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---+---+---+---+---+----+---+---+----+---+---+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "|05db9164|711ec2bc|40862c01|9181b362|0f39538f|07d13a8f|10040656|f05e9fe4|e5ba7672|891589e7|3be24715|287130e0|a458ea53|8dd62c87|        |32c7478e|3fdb382b|ea9a246c|49d68486|167110dc|72aea73c|25c83c98|6f6d9be8|3eec36fc|5b392875|a73ee510|  0|  0|  1|   |   |   1|  4|   |5947| 61|  4|  3| 54|    0|(262144,[7735,882...|[4.80909115783803...|[0.99191070221071...|       0.0|\n",
      "|05db9164|b5f7cd48|3407cf7b|6c1eaacd|f0fe287d|07d13a8f|075f843b|ad48368b|07c540c4|744ad4a0|        |3f0d3f28|        |6366c678|ad3062eb|423fab69|e5fca70a|        |        |0eb4724f|b40012b1|4cf72387|fe6b92e5|2f1a67ee|0b153874|a73ee510|  0|  0|  1|   |   |1794|   |   |1316|104|  1| 14| 94|    1|(262144,[36853,47...|[2.78939346865303...|[0.94209996875389...|       0.0|\n",
      "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---+---+---+---+---+----+---+---+----+---+---+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(featurizedTest)\n",
    "predictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- C1: string (nullable = true)\n",
      " |-- C10: string (nullable = true)\n",
      " |-- C11: string (nullable = true)\n",
      " |-- C12: string (nullable = true)\n",
      " |-- C13: string (nullable = true)\n",
      " |-- C14: string (nullable = true)\n",
      " |-- C15: string (nullable = true)\n",
      " |-- C16: string (nullable = true)\n",
      " |-- C17: string (nullable = true)\n",
      " |-- C18: string (nullable = true)\n",
      " |-- C19: string (nullable = true)\n",
      " |-- C2: string (nullable = true)\n",
      " |-- C20: string (nullable = true)\n",
      " |-- C21: string (nullable = true)\n",
      " |-- C22: string (nullable = true)\n",
      " |-- C23: string (nullable = true)\n",
      " |-- C24: string (nullable = true)\n",
      " |-- C25: string (nullable = true)\n",
      " |-- C26: string (nullable = true)\n",
      " |-- C3: string (nullable = true)\n",
      " |-- C4: string (nullable = true)\n",
      " |-- C5: string (nullable = true)\n",
      " |-- C6: string (nullable = true)\n",
      " |-- C7: string (nullable = true)\n",
      " |-- C8: string (nullable = true)\n",
      " |-- C9: string (nullable = true)\n",
      " |-- I1: string (nullable = true)\n",
      " |-- I10: string (nullable = true)\n",
      " |-- I11: string (nullable = true)\n",
      " |-- I12: string (nullable = true)\n",
      " |-- I13: string (nullable = true)\n",
      " |-- I2: string (nullable = true)\n",
      " |-- I3: string (nullable = true)\n",
      " |-- I4: string (nullable = true)\n",
      " |-- I5: string (nullable = true)\n",
      " |-- I6: string (nullable = true)\n",
      " |-- I7: string (nullable = true)\n",
      " |-- I8: string (nullable = true)\n",
      " |-- I9: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()\n",
    "predictions.select(\"prediction\").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---+---+---+---+---+----+---+---+----+---+---+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "|      C1|     C10|     C11|     C12|     C13|     C14|     C15|     C16|     C17|     C18|     C19|      C2|     C20|     C21|     C22|     C23|     C24|     C25|     C26|      C3|      C4|      C5|      C6|      C7|      C8|      C9| I1|I10|I11|I12|I13|  I2| I3| I4|  I5| I6| I7| I8| I9|label|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---+---+---+---+---+----+---+---+----+---+---+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "|05db9164|711ec2bc|40862c01|9181b362|0f39538f|07d13a8f|10040656|f05e9fe4|e5ba7672|891589e7|3be24715|287130e0|a458ea53|8dd62c87|        |32c7478e|3fdb382b|ea9a246c|49d68486|167110dc|72aea73c|25c83c98|6f6d9be8|3eec36fc|5b392875|a73ee510|  0|  0|  1|   |   |   1|  4|   |5947| 61|  4|  3| 54|    0|(262144,[7735,882...|[4.80909115783803...|[0.99191070221071...|       0.0|\n",
      "|05db9164|b5f7cd48|3407cf7b|6c1eaacd|f0fe287d|07d13a8f|075f843b|ad48368b|07c540c4|744ad4a0|        |3f0d3f28|        |6366c678|ad3062eb|423fab69|e5fca70a|        |        |0eb4724f|b40012b1|4cf72387|fe6b92e5|2f1a67ee|0b153874|a73ee510|  0|  0|  1|   |   |1794|   |   |1316|104|  1| 14| 94|    1|(262144,[36853,47...|[2.78939346865303...|[0.94209996875389...|       0.0|\n",
      "|05db9164|3b08e48b|a6925b63|231eed81|d9946b7d|b28479f6|52baadf5|694ffb8a|27c07bd6|5aed7436|88a49bd9|09e68b86|a458ea53|1254515c|        |32c7478e|1793a828|e8b83407|715e5a98|9f34f60a|eeabb36d|43b19349|        |ce51213c|37e4aa92|a73ee510|   |   |  0|  4|  7|   1| 69|  7| 672|   |  0|  8| 71|    0|(262144,[6050,286...|[7.52148781022090...|[0.99945896630071...|       0.0|\n",
      "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---+---+---+---+---+----+---+---+----+---+---+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Intercept:  -1.539475798610839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Feature Weight: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Feature Weight|\n",
      "+--------------+\n",
      "|           0.0|\n",
      "|           0.0|\n",
      "+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(lr.explainParams())\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"label\")\n",
    "evaluator.evaluate(predictions)\n",
    "evaluator.getMetricName()\n",
    "print('Model Intercept: ', lrModel.intercept)\n",
    "weights = lrModel.coefficients\n",
    "weights = [(float(w),) for w in weights]  # convert numpy type to float, and to tuple\n",
    "weightsDF = sqlContext.createDataFrame(weights, [\"Feature Weight\"])\n",
    "display(weightsDF)\n",
    "weightsDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946703513620213"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"label\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
